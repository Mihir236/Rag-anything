{
  "doc-4bc246de7250bdedc12647a6b8803374": {
    "content": "CS791- Comprehensive viva \n\nMulti-Agent System for Intelligent Query Processing \n\nPresented by, \n\nMihir Modi- 202462001, \n\nMTech (3rd Semester) in DS \n\nInternal Guide, Guided by, Dr. Ravi Nahta Mukesh Siroya \n\nOverview \n\nIntroduction   \nProblem Definition   \nMotivation   \nWorkflow Diagram   \nImplementation Details   \nPDF Chatboard Extension   \nMulti-Modal Extension   \nAgentic RAG Extension   \nAPIs List   \nInitial Results   \nConclusion   \nFuture Work   \nReference \n\nOverview: A Python-based multi-agent system integrating weather, GitHub, Q&A, PDF querying, image analysis, and agentic RAG for intelligent, multi-domain query processing. \n\nKey Features: \n\n• Typo correction (e.g., \"Ahmmedabad\" \"Ahmedabad\") using NVIDIA LLaMA-3 Asynchronous processing with asyncio for speed Modular agents: WeatherAgent, GitHubAgent, QAAgent Extensions: PDF Chatboard, Multi-Modal Image Analysis, Agentic RAG with evaluati \n\nObjective: Deliver scalable, accurate, user-friendly query resolution. \n\nScope: Leverages NVIDIA, Gemini, WeatherAPI, and GitHub API in Google Colab \n\nGiven: Diverse user queries across domains (weather, repositories, general knowledge, documents, images) \n\nObjective: Provide structured, efficient responses with minimal user effort \n\nChallenges: \n\nVaried Query Styles: Inconsistent inputs (e.g., \"Patan temp\" vs. \"weather in Patan\")   \nAPI Restrictions: Rate limits and potential failures   \nScalability: Handle multiple simultaneous queries quickly   \nAccuracy: Correct typos and resolve ambiguous inputs \n\nGoal: Build an AI-driven, typo-correcting, scalable query processing system \n\nWhy It Matters: Fast, accurate information access is critical for decision-making in education, software development, and daily planning \n\nReal-World Impact: \n\nSoftware Development: Quick GitHub repo insights for collaboration Education: Reliable answers for students and researchers Daily Use: Real-time weather for planning (e.g., city storm response) \n\nBenefits: \n\nModularity: Easy to add new agents Efficiency: Async processing and caching User-Friendly: Typo correction and suggestions Extensibility: Supports new APIs and tasks \n\nWorkFlow Diagram \n\nImplementation Details \n\nEnvironment: Google Colab, Python $3 . 1 0 +$ , asyncio for asynchronous processing. \n\nKey Libraries: \n\nCore: langchain, langgraph, faiss-cpu, ragas, PyPDF2, google-generativeai.   \nSupport: requests, beautifulsoup4, pillow, pydantic, nest_asyncio, backoff. \n\nTechniques: \n\nAsync I/O for parallel query handling.   \nFAISS vector store for efficient retrieval.   \nPickle-based caching for API call reduction.   \nBackoff retries for robust API interactions. \n\nKey Functions: \n\ncorrect_spelling(): Typo correction via NVIDIA LLaMA-3.   \nprocess_query(): Agent-specific logic.   \nmain(): Async console interface. \n\nPDF Chatboard Extension \n\nWhat: Console-based tool for uploading and querying PDFs. \n\nWhy: Enables document-specific Q&A for research and education \n\nHow: \n\nUploads PDFs via google.colab.files   \nExtracts text with PyPDF2 and cleans using regex   \nAnswers queries with NVIDIA LLaMA-3.1-8B-Instruct via OpenAI SDK. \n\nKey Functions: \n\nsave_pdf_to_local(): Saves uploaded PDFs   \nextract_text_from_pdf(): Processes text   \ngenerate_answer(): Delivers concise responses (1-2 sentences) \n\nExample: Query “What is NLP?” on a PDF yields concise answer \n\nPDF Chatboard Output \n\nYour query: what is svm，give me ans from svm.pdf I believe you meant:'What is SVM? Give me an answer from SVM.pdf' \n\n□ Answer (Source:PDF Chatboard (RAG on SVM.pdf)): \n\nHere is a concise answer: \n\nSVstandsforisaaiiaoaetetn === \n\nYour query: what is svm , give me ans from svm.pdf I believe you meant: 'What is SVM? Give me an answer from SVM.pdf' \n\nAnswer (Source: PDF Chatboard (RAG on SVM.pdf)): \n\nis a concise answer: SVM stands for Support Vector Machines, which is a binary classification technique that aims to maximize the margin between two classes by finding the optimal hyperplane that separates them. The SVM decision function can als be represented as a linear programming problem, allowing for the generalization of th optimization problem to multi-class classification. \n\nWhat: Analyzes .jpg/.png images using Gemini 2.5 Flash or local fallback \n\nWhy: Provides structured visual analysis for diverse applications \n\nHow: \n\nUploads images via google.colab.files Gemini API for detailed analysis (scene, objects, colors, environment) Local PIL-based fallback for API failures (metadata analysis) \n\nKey Functions: \n\nVisionAnalyzer.setup_gemini(): Initializes Gemini model gemini_vision_analysis(): Structured image analysis advanced_local_vision(): Fallback for offline processing \n\nMulti-Modal Output \n\nYour query: how may boats inimage_trial.png? $\\mathfrak { Q }$ Analyzingimage_trial.png.. \n\nAnswer (SOurce: GEMINI 2.5 VISION ANALYSIS): \n\nThere are \\*\\*2\\*\\* boats visible in the image. \n\nAgentic RAG \n\nWhat: Retrieval-Augmented Generation with evaluation \n\nWhy: Enhances Q&A with context-aware, evaluated responses \n\nHow RAG Works \n\nRetrieval Step: \n\nWhen a user queries a PDF (e.g., “Explain backpropagation in SVM.pdf”), the system: \n\nExtracts text using PyPDF2.   \nSplits it into manageable overlapping chunks using RecursiveCharacterTextSplitter.   \nEncodes each chunk into numerical embeddings using NVIDIA nv-embedqa-e5-v5 embeddings.   \nStores and searches these embeddings in a FAISS vector database to find top relevant content. \n\n• Augmentation Step: \n\n• The top-k retrieved chunks (typically 3) act as factual context.   \n• The summarize_context() function trims or summarizes this context to fit token limits using LLaMA-3.1-8B. \n\nGeneration Step: \n\n• The model (Mixtral-8x22B) is prompted with both the user query and retrieved context. • It produces an informed, concise answer consistent with the underlying document \n\nChallenges: \n\nAPI Rate Limits: Frequent API calls lead to throttling Typo Handling: Misspelled queries (e.g., \"Mehasana\" vs. \"Mehsana\") Async Complexity: Managing concurrent tasks in Colab Data Scalability: Processing large PDFs or image datasets \n\nSolutions: \n\nCaching: Pickle-based response caching to reduce API calls Typo Correction: NVIDIA LLaMA-3 for spelling fixes Asyncio: Parallel query processing with nest_asyncio Modular Design: FAISS and LangGraph for scalable retrieval \n\nResults \n\nEfficiency: Python’s asyncio saving time and resources for all queries. \n\nSpeed: Delivers fast responses using asynchronous processing, ensuring quick results for any task. \n\nAccuracy: Achieves high reliability, with the Weather Agent being more accurate for cities worldwide. \n\nSmart Correction: Using Pre_train(LLaMA-3) model’s API calls to fixes typos (e.g., \"temp\" to \"temperature\") to improve results for any query. \n\nEvaluation Results: {'faithfulness': 0.8333, 'answer_relevancy': 0.4270, 'context_precision': 0.6667, 'context_recall': 0.4444, 'answer_correctness': 0.7224} \n\nKey Achievements: \n\nIntegrated WeatherAPI, GitHub API, NVIDIA API, and Gemini API Scalable multi-agent system with typo correction and async processing Extended with PDF querying, image analysis, and evaluated RAG \n\nImpact: \n\nEnhances real-time access for education, development, and planning Demonstrates robust, modular AI system design \n\nTakeaway: Unified platform for intelligent, multi-domain query processing \n\nAdditional Agents: \n\nStock market data retrieval (real-time stock prices) News summary agent for current events \n\nActionable Agents: \n\nTasks like sending emails or updating databases Example: Weather-based appointment booking. \n\nReferences \n\n LangChain Academy. (n.d.). Intro to LangGraph. https://academy.langchain.com/courses/intro-to-langgraph \n\nByteByteGo. (n.d.). GenAI System Design Interview: Introduction and Overview. https://bytebytego.com/courses/genai-sy stem-design-interview/introduction-and-overview \n\nKarpathy, A. (n.d.). YouTube Playlists. https://www.youtube.com/ $@$ AndrejKarpathy/playlists \n\nYouTube Video. (n.d.). LangChain Tutorial. https://youtu.be/wMVzCctmtLI \n\n Fan, Y., Ma, X., Wu, R., Du, Y., Li, J., Gao, Z., & Li, Q. (2025). VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding. https://arxiv.org/abs/2410.00000 \n\nLlama Team. (2024, July 23). The Llama 3 Herd of Models (Version 3). arXiv preprint arXiv:2407.21783. https://arxiv.org/abs/2407.21783 \n\nThank You!",
    "file_path": "viva.pptx",
    "create_time": 1766750837,
    "update_time": 1766750837,
    "_id": "doc-4bc246de7250bdedc12647a6b8803374"
  }
}